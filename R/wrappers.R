#' Estimating a Statistical Model
#'
#' The zelig command estimates a variety of statistical
#' models.  Use \code{zelig} output with \code{setx} and \code{sim} to compute
#' quantities of interest, such as predicted probabilities, expected values, and
#' first differences, along with the associated measures of uncertainty
#' (standard errors and confidence intervals).
#'
#' @param formula a symbolic representation of the model to be
#'   estimated, in the form \code{y \~\, x1 + x2}, where \code{y} is the
#'   dependent variable and \code{x1} and \code{x2} are the explanatory
#'   variables, and \code{y}, \code{x1}, and \code{x2} are contained in the
#'   same dataset.  (You may include more than two explanatory variables,
#'   of course.)  The \code{+} symbol means ``inclusion'' not
#'   ``addition.''  You may also include interaction terms and main
#'   effects in the form \code{x1*x2} without computing them in prior
#'   steps; \code{I(x1*x2)} to include only the interaction term and
#'   exclude the main effects; and quadratic terms in the form
#'   \code{I(x1^2)}
#' @param model the name of a statistical model.
#'   Type \code{help.zelig("models")} to see a list of currently supported
#'   models
#' @param data the name of a data frame containing the variables
#'   referenced in the formula, or a list of multiply imputed data frames
#'   each having the same variable names and row numbers (created by
#'   \code{mi}) 
#' @param ... additional arguments passed to \code{zelig},
#'   depending on the model to be estimated
#' @param by a factor variable contained in \code{data}.  Zelig will subset
#'   the data frame based on the levels in the \code{by} variable, and
#'   estimate a model for each subset.  This a particularly powerful option
#'   which will allow you to save a considerable amount of effort.  For
#'   example, to run the same model on all fifty states, you could type:
#'   \code{z.out <- zelig(y ~ x1 + x2, data = mydata, model = "ls", by = "state")}
#'   You may also use \code{by} to run models using MatchIt subclass
#' @param cite If is set to "TRUE" (default), the model citation will be
#' @return Depending on the class of model selected, \code{zelig} will return
#'   an object with elements including \code{coefficients}, \code{residuals},
#'   and \code{formula} which may be summarized using
#'   \code{summary(z.out)} or individually extracted using, for example,
#'   \code{z.out\$coefficients}.  See the specific models listed above
#'   for additional output values, or simply type \code{names(z.out)}.  
#'
#' @name zelig
#' @export
#' @author Matt Owen \email{mowen@@iq.harvard.edu}, Kosuke Imai, Olivia Lau, and
#' Gary King 
#' Maintainer: Matt Owen \email{mowen@@iq.harvard.edu}
#' @keywords package

zelig <- function(formula, model, data, ..., by = NULL, cite = TRUE) {
  #   .Deprecated("\nz$new() \nz$zelig(...)")
  # Zelig Core
  models <- zmodelsAvailable()
  models4 <- list()
  for (i in seq(models)) {
    models4[[models[[i]]$wrapper]] <- names(models)[i]
  }
  model.init <- paste0("z", models4[[model]], "$new()")
  z5 <- try(eval(parse(text = model.init)), silent = TRUE)
  if ("try-error" %in% class(z5))
    stop("Model '", model,"' not found")
  ## End: Zelig 5 models
  mf <- match.call()
  mf$model <- NULL
  mf$cite <- NULL
  mf[[1]] <- quote(z5$zelig)
  mf <- try(eval(mf, environment()), silent = TRUE)
  if ("try-error" %in% class(mf))
    z5$zelig(formula = formula, data = data, ..., by = by)
  if (cite)
    z5$cite()
  return(z5)
}

#' Setting Explanatory Variable Values
#'
#' The \code{setx} command uses the variables identified in
#' the \code{formula} generated by \code{zelig} and sets the values of
#' the explanatory variables to the selected values.  Use \code{setx}
#' after \code{zelig} and before \code{sim} to simulate quantities of
#' interest.
#' @param obj the saved output from zelig
#' @param fn a list of functions to apply to the data frame
#' @param data a new data frame used to set the values of
#'   explanatory variables. If data = NULL (the default), the
#'   data frame called in zelig is used
#' @param cond   a logical value indicating whether unconditional
#'   (default) or conditional (choose \code{cond = TRUE}) prediction
#'   should be performed.  If you choose \code{cond = TRUE}, \code{setx}
#'   will coerce \code{fn = NULL} and ignore the additional arguments in 
#'   \code{\dots}.  If \code{cond = TRUE} and \code{data = NULL},
#'   \code{setx} will prompt you for a data frame.
#' @param ... user-defined values of specific variables for overwriting the
#'   default values set by the function \code{fn}.  For example, adding
#'   \code{var1 = mean(data\$var1)} or \code{x1 = 12} explicitly sets the value
#'   of \code{x1} to 12.  In addition, you may specify one explanatory variable
#'   as a range of values, creating one observation for every unique value in
#'   the range of values
#' @return For unconditional prediction, \code{x.out} is a model matrix based
#'   on the specified values for the explanatory variables.  For multiple
#'   analyses (i.e., when choosing the \code{by} option in \code{\link{zelig}},
#'   \code{setx} returns the selected values calculated over the entire
#'   data frame.  If you wish to calculate values over just one subset of
#'   the data frame, the 5th subset for example, you may use:  
#'   \code{x.out <- setx(z.out[[5]])}
#' @export
#' @examples
#'
#' # Unconditional prediction:
#' data(turnout)
#' z.out <- zelig(vote ~ race + educate, model = "logit", data = turnout)
#' x.out <- setx(z.out)
#' s.out <- sim(z.out, x = x.out)
#'
#' @author Matt Owen \email{mowen@@iq.harvard.edu}, Olivia Lau and Kosuke Imai 
#' @seealso The full Zelig manual may be accessed online at
#'   \url{http://gking.harvard.edu/zelig}
#' @keywords file

setx <- function(obj, fn = NULL, data = NULL, cond = FALSE, ...) {
  # .Deprecated("\nz$new() \nz$zelig(...) \nz$setx() or z$setx1 or z$setrange")
  x5 <- obj$copy()
  # This is the length of each argument in '...'s
  s <- list(...)
  if (length(s) > 0) {
    hold <- rep(1, length(s))
    for(i in 1:length(s)) {
      hold[i] <- length(s[i][[1]])
    }
  } else {
    hold <- 1
  }
  if (max(hold) > 1) {
    x5$setrange(...)
  } else {
    x5$setx(...)
  }
  return(x5)
}

#' Generic Method for Computing and Organizing Simulated Quantities of Interest
#' 
#' Simulate quantities of interest from the estimated model
#' output from \code{zelig()} given specified values of explanatory
#' variables established in \code{setx()}.  For classical \emph{maximum
#' likelihood} models, \code{sim()} uses asymptotic normal
#' approximation to the log-likelihood.  For \emph{Bayesian models},
#' Zelig simulates quantities of interest from the posterior density,
#' whenever possible.  For \emph{robust Bayesian models}, simulations
#' are drawn from the identified class of Bayesian posteriors.
#' Alternatively, you may generate quantities of interest using
#' bootstrapped parameters.
#' @param obj the output object from zelig
#' @param x values of explanatory variables used for simulation,
#'   generated by setx
#' @param x1 optional values of explanatory variables (generated by a
#'   second call of setx)
#'           particular computations of quantities of interest
#' @param y a parameter reserved for the computation of particular
#'          quantities of interest (average treatment effects). Few
#'          models currently support this parameter
#' @param num an integer specifying the number of simulations to compute
#' @param bootstrap currently unsupported
#' @param bootfn currently unsupported
#' @param cond.data currently unsupported
#' @param ... arguments reserved future versions of Zelig
#' @return The output stored in \code{s.out} varies by model.  Use the
#'  \code{names} command to view the output stored in \code{s.out}.
#'  Common elements include: 
#'  \item{x}{the \code{\link{setx}} values for the explanatory variables,
#'    used to calculate the quantities of interest (expected values,
#'    predicted values, etc.). }
#'  \item{x1}{the optional \code{\link{setx}} object used to simulate
#'    first differences, and other model-specific quantities of
#'    interest, such as risk-ratios.}
#'  \item{call}{the options selected for \code{\link{sim}}, used to
#'    replicate quantities of interest. } 
#'  \item{zelig.call}{the original command and options for
#'    \code{\link{zelig}}, used to replicate analyses. }
#'  \item{num}{the number of simulations requested. }
#'  \item{par}{the parameters (coefficients, and additional
#'    model-specific parameters).  You may wish to use the same set of
#'    simulated parameters to calculate quantities of interest rather
#'    than simulating another set.}
#'  \item{qi\$ev}{simulations of the expected values given the
#'    model and \code{x}. }
#'  \item{qi\$pr}{simulations of the predicted values given by the
#'    fitted values. }
#'  \item{qi\$fd}{simulations of the first differences (or risk
#'    difference for binary models) for the given \code{x} and \code{x1}.
#'    The difference is calculated by subtracting the expected values
#'    given \code{x} from the expected values given \code{x1}.  (If do not
#'    specify \code{x1}, you will not get first differences or risk
#'    ratios.) }
#'  \item{qi\$rr}{simulations of the risk ratios for binary and
#'    multinomial models.  See specific models for details.}
#'  \item{qi\$ate.ev}{simulations of the average expected
#'    treatment effect for the treatment group, using conditional
#'    prediction. Let \eqn{t_i} be a binary explanatory variable defining
#'    the treatment (\eqn{t_i=1}) and control (\eqn{t_i=0}) groups.  Then the
#'    average expected treatment effect for the treatment group is
#'    \deqn{ \frac{1}{n}\sum_{i=1}^n [ \, Y_i(t_i=1) -
#'      E[Y_i(t_i=0)] \mid t_i=1 \,],} 
#'    where \eqn{Y_i(t_i=1)} is the value of the dependent variable for
#'    observation \eqn{i} in the treatment group.  Variation in the
#'    simulations are due to uncertainty in simulating \eqn{E[Y_i(t_i=0)]},
#'    the counterfactual expected value of \eqn{Y_i} for observations in the
#'    treatment group, under the assumption that everything stays the
#'    same except that the treatment indicator is switched to \eqn{t_i=0}. }
#'  \item{qi\$ate.pr}{simulations of the average predicted
#'    treatment effect for the treatment group, using conditional
#'    prediction. Let \eqn{t_i} be a binary explanatory variable defining
#'    the treatment (\eqn{t_i=1}) and control (\eqn{t_i=0}) groups.  Then the
#'    average predicted treatment effect for the treatment group is
#'    \deqn{ \frac{1}{n}\sum_{i=1}^n [ \, Y_i(t_i=1) -
#'      \widehat{Y_i(t_i=0)} \mid t_i=1 \,],} 
#'    where \eqn{Y_i(t_i=1)} is the value of the dependent variable for
#'    observation \eqn{i} in the treatment group.  Variation in the
#'    simulations are due to uncertainty in simulating
#'    \eqn{\widehat{Y_i(t_i=0)}}, the counterfactual predicted value of
#'    \eqn{Y_i} for observations in the treatment group, under the
#'    assumption that everything stays the same except that the
#'    treatment indicator is switched to \eqn{t_i=0}.}
#' @export
#' @author Matt Owen \email{mowen@@iq.harvard.edu}, Olivia Lau and Kosuke Imai 


sim <- function(obj, x = NULL, x1 = NULL, y = NULL, num = 1000, bootstrap = F, 
                bootfn = NULL, cond.data = NULL, ...) {
  # .Deprecated("\nz$new() \n[...] \nz$sim(...)")
  s5 <- x$copy()
  if (!is.null(x1)) {
    s15 <- x1$copy()
    if (!is.null(s15$setx.out$x)) {
      s5$setx.out$x1 <- s15$setx.out$x
      s5$bsetx1 <- TRUE
    }
    if (!is.null(s15$setx.out$range)) {
      s5$range1<-s15$range
      s5$setx.out$range1 <- s15$setx.out$range
      s5$bsetrange1 <- TRUE
    }
  }
  s5$sim(num = num)
  return(s5)
}

#' Extract quantities of interest from a Zelig model
#' 

#' @param z.out the output object from zelig
#' @param nsim the number of simulations used
#' @return A list containing data.frames with columns stroring covariate values
#'   and quantities of interest. Specifically,
#'   \item{at} A data.frame with
#'   quantities of interest at specific covariate value and possibly
#'   \item{fd_at}{A data.frame with differences in quantities of interest at a
#'   set of covariate values}
get_all_qi <- function(z.out, nsim) {
  x.out.tmp <- z.out$setx.out
  ## browser()
  ##                                       # if(length(x.out.tmp) >1) x.out.tmp <- do.call(c, x.out.tmp)
  ## if("range" %in% names(x.out.tmp)) x.out.tmp <- x.out.tmp[[1]]
  ## x.out <- do.call(rbind,
  ##                  lapply(x.out.tmp,
  ##                         function(x) {
  ##                           do.call(rbind,
  ##                                   lapply(x[[2]],
  ##                                          as.data.frame))
  ##                         }))
  x.out <- bind_rows(lapply(names(x.out.tmp),
                            function(x) {
                              bind_rows(lapply(x.out.tmp[[x]][[2]],
                                               function(y) {
                                                 mutate(as.data.frame(y,
                                                                      stringsAsFactors = FALSE),
                                                        zelig__source = x)
                                               }))
                            }))
  s.out <- bind_rows(lapply(names(z.out$sim.out),
                            function(x) {
                              bind_rows(
                                lapply(c(names(z.out$sim.out[[x]]), names(z.out$sim.out[[x]][[1]])),
                                       function(y) {
                                         mutate(
                                           setNames(
                                             as.data.frame(z.out$getqi(qi = y, xvalue = x),
                                                           stringsAsFactors = FALSE),
                                             "value"),
                                           zelig__source = x,
                                           type = y)
                                       }))
                            }))
  if("x" %in% x.out$zelig__source && "x1" %in% x.out$zelig__source) {
    x.out <- list(
      x.at = x.out,
      x.fd_at = as.data.frame(sapply(x.out,
                                     function(x)
                                     {
                                       if(is.numeric(x)) x <- round(x, digits = 4)
                                       paste(substr(x, 1, 4), sep = "", collapse = " :VS: ")
                                     },
                                     simplify = FALSE),
                              check.names = FALSE))
    s.out <- list(s.at = droplevels(s.out[s.out$type != "fd", ]),
                  s.fd_at = droplevels(transform(s.out[s.out$type == "fd", ], zelig__source = "x :VS: x1")))
    simqi <- list(at = merge(x.out[[1]], s.out[[1]]),
                  fd_at = merge(x.out[[2]], s.out[[2]]))
  } else {
    simqi <- list(at = merge(x.out, s.out))
  }
  simqi <- sapply(simqi, function(x) {
    drop(transform(x[, setdiff(names(x), "(Intercept)")],
                   type = factor(type,
                                 levels = c("pv", "ev", "fd"),
                                 labels = c("Predicted values", "Expected values", "Difference in Expected Values"))))
  },
  simplify = FALSE)
  class(simqi) <- c("qidist", class(simqi))
  return(simqi)
}

#' Simulated distributions of quantities of interest.
#' 
#' This is a generic function. Currently the only useful method is for lm
#' models.
#' @param model A model fit object
#' @param nsim the number of simulations used
#' @param ... arguments passed to methods
#' @return A list containing data.frames with columns stroring covariate values
#'   and quantities of interest. Specifically,
#'   \item{at} A data.frame with
#'   quantities of interest at specific covariate value and possibly
#'   \item{fd_at}{A data.frame with differences in quantities of interest at a
#'   set of covariate values}
#' @export
  qi_dist <- function(model, nsim = 1000, ...) {
  UseMethod("qi_dist")
}

#' Simulated distributions of quantities of interest from lm and glm models.
#' 
#' @param model A model fit object
#' @param at A named list of covariate values.
#' @param fd_at A list of length 2. Each element must itself be a named list of covariate values.
#' @param nsim The number of simulations used
#' @return A list containing data.frames with columns stroring covariate values
#'   and quantities of interest. Specifically,
#'   \item{at} {A data.frame with simulated
#'   quantities of interest at specific covariate value}
#'   and possibly
#'   \item{fd_at}{A data.frame with differences in quantities of interest at a
#'   set of covariate values}
#' @export
#' @rdname qi_dist
qi_dist.lm <- function(model, at = list(), fd_at = list(x1 = NULL, x2 = NULL), nsim = 1000) {
  z <- zmodelMatcher(model)
  z.out <- z$zelig
  do.call(z.out$zelig, z$model.args)
  if(!all(sapply(fd_at, is.null))) {
    if(length(at) >0) warning("'at' and 'fd_at' both specified: ignoring 'at'.")
    do.call(z.out$setx, fd_at$x1)
    do.call(z.out$setx1, fd_at$x2)
    z.out$sim(num = nsim)
    return(get_all_qi(z.out, nsim = nsim))
  }
  by <- rowwise(do.call(expand.grid, at))
  by.names <- names(by)
  simqi <- vector(mode = "list", length = nrow(by))
  for(i in 1:nrow(by)) {
    by.i <- as.list(by[i, , drop = TRUE])
    do.call(z.out$setx, by.i)
    z.out$sim(num = nsim)
    simqi[[i]] <- get_all_qi(z.out, nsim = nsim)
    simqi[[i]] <- sapply(simqi[[i]], function(x) {
      for(j in by.names) x[[j]] <- by.i[[j]]
      return(x)
    },
    simplify = FALSE)
  }
  simqi_at <- do.call(rbind, sapply(simqi, function(x) x[["at"]], simplify = FALSE))
  if("fd_at" %in% names(simqi)) {
    simqi_fd_at <- do.call(rbind, sapply(simqi, function(x) x[["fd_at"]], simplify = FALSE))
    simqi_at <- list(at = simqi_at, fd_at = simqi_fd_att)
  } else {
    simqi_at <- list(at = simqi_at)
  }
  class(simqi_at) <- c("qidist", class(simqi_at))
  return(simqi_at)
}


#' Summary statistic from distributions of quantities of interest.
#' 
#' @param x A list containing distributions of quantities of interest.
#' @param probs probabilities passed to quantile.
#' @param fd_at A list of length 2. Each element must itself be a named list of covariate values.
#' @param nsim The number of simulations used
#' @return A list containing data.frames with columns stroring covariate values
#'   and summry statistic for quantities of interest. Specifically,
#'   \item{at} {A data.frame with simulated statistics for
#'   quantities of interest at specific covariate values}
#'   and possibly
#'   \item{fd_at}{A data.frame with summaries of differences in quantities of interest at a
#'   set of covariate values}
#' @export
summary.qidist <- function(x, probs = c(0.025, 0.50, 0.975)) {
  qi_dist <- sapply(x, function(y) {
    aggregate(y$value,
              by = as.list(y[setdiff(names(y), "value")]),
              FUN = function(y) c(mean = mean(y), sd = sd(y), quantile(y, probs = probs)))
  },
  simplify = FALSE)
  qi_dist <- sapply(qi_dist,
                    function(foo) {
                      tmp <- data.frame(foo[["x"]])
                      names(tmp) <- gsub("^X", "qp_", names(tmp))
                      names(tmp) <- gsub("\\.$", "", names(tmp))
                      cbind(foo[, setdiff(names(foo), "x")], tmp)
                    },
                    simplify = FALSE)
  class(qi_dist) <- c("qidist_summary", class(qi_dist))
  return(qi_dist)
}

#' Plot distributions of quantities of interest.
#' 
#' @param qi_dist A list containing distributions of quantities of interest.
#' @return A ggplot object.
#' @export
plot.qidist <- function(qi_dist) {
  ## This could resonably by re-factored into simulation.plot or so.
  qi_dist[] <- sapply(qi_dist, function(x) x[, !grepl(":", names(x))], simplify = FALSE)
  varnames <- setdiff(names(qi_dist[[1]]), c("value", "type", "zelig__source"))
  varlen <- sapply(qi_dist[[1]][, varnames, drop = FALSE], function(x) length(unique(x)))
  varnames <- varnames[order(varlen, decreasing = TRUE)]
  varlen <- varlen[order(varlen, decreasing = TRUE)]
  diffvars <- varnames[varlen > 1]
  staticvars <- setdiff(varnames, diffvars)
  staticvals <- sapply(qi_dist[[1]][, staticvars, drop = FALSE], unique)
  diffvar <- diffvars[1]
  if(length(diffvars) > 1) diffvars <- setdiff(diffvars, diffvar)
  minpos <- aggregate(qi_dist[[1]]["value"],
                      by = as.list(qi_dist[[1]][c("type", staticvars)]),
                      FUN = min)
  minpos$othervars <- rep(paste(paste(staticvars, staticvals, sep = " = "), collapse = "\n"), nrow(minpos))
  foo <- sapply(diffvars, function(x) {
    col <- qi_dist[[1]][[x]]
    if(is.numeric(col)) col <- as.character(round(col, digits = 2))
    paste(x, col, sep = " = ")
  })
  if(is.matrix(foo) && ncol(foo) > 1) foo <- apply(foo, 1, paste, collapse = ",")
  qi_dist[[1]][["covars"]] <- paste("(", qi_dist[[1]][["type"]], " | ", foo, ")", sep = "")
  diffvars <- setdiff(diffvars, diffvar)
  if(max(varlen) <= 2) {
    p <- ggplot(qi_dist[[1]],
                aes(x = value),
                alpha = 0.125) +
      geom_density(aes_string(y = "..scaled..", fill = "covars", color = "covars"), alpha = 0.125, size = 1) +
      geom_text(aes(y = 0.9, label =  othervars), hjust = 0, data = minpos)
    if(length(unique(qi_dist[[1]][["covars"]])) >5 && length(diffvars) > 0) {
      p <- p + facet_grid(as.formula(paste(diffvar, "~ type", collapse = "")), scales = "free", labeller = "label_both") +
        scale_y_continuous(limits = c(0, 1.35))
    } else {
      p <- p + facet_wrap(~type, ncol = 1, scales = "free") +
        scale_y_continuous(limits = c(0, 1.1))
    }
    if("fd_at" %in% names(qi_dist)) {
      qi_dist[[2]]$covars <- NA
      p <- p + geom_density(aes_string(y = "..scaled..", fill = "covars"), data = qi_dist[[2]], alpha = 0.125, size = 1, color = "gray60")
    }
    ggp <- any(grepl("ggplot2", search()))
    if(!ggp) require(ggplot2, quietly = TRUE) ## not sure why the import system isn't finding this.
    p <- direct.label(p +
                      theme(legend.position = "top"),
                      method = "top.bumptwice")
    if(!ggp) detach(package:ggplot2)
  } else {
    pdat <- summary(qi_dist)[[1]]
    if (max(varlen) < 10) {
      pdat[[diffvar]] <- factor(pdat[[diffvar]])
      p <- ggplot(pdat, aes_string(x = diffvar, y = "mean"))
      if(length(diffvars) > 0) {
        p <- p + geom_errorbar(aes(ymin = qp_2.5, ymax = qp_97.5,
                               color = covars),
                           stat = "identity") 
      } else {
        p <- p + geom_errorbar(aes(ymin = qp_2.5, ymax = qp_97.5),
                           stat = "identity")
      }
    } else {
      p <- ggplot(pdat, aes_string(x = diffvar, y = "mean"))
      if(length(diffvars) >0) {
        p <- p + geom_smooth(aes(ymin = qp_2.5, ymax = qp_97.5,
                                 color = covars), stat = "identity")
      } else {
        p <- p + geom_smooth(aes(ymin = qp_2.5, ymax = qp_97.5),
                             stat = "identity")
      }
    }
    p <- p +
      facet_wrap(~type) +
      theme(legend.position = "top")
  }
  return(p)
}

